{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== IMPORT LIBRARIES ===========\n",
    "from utils.utils import *\n",
    "import pickle\n",
    "from skseq import structured_perceptron_c\n",
    "from skseq.structured_perceptron import StructuredPerceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_transform_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['words'] = df['words'].astype(str)\n",
    "    X, y = transform_data_sentence_tag(df)\n",
    "    return X, y\n",
    "\n",
    "# Dictionary to store the data\n",
    "data_files = {\n",
    "    \"train\": \"data/train_data_ner.csv\",\n",
    "    \"test\": \"data/test_data_ner.csv\",\n",
    "    \"tiny\": \"data/tiny_test.csv\"\n",
    "}\n",
    "\n",
    "save_models=True\n",
    "if save_models==True:\n",
    "    \n",
    "    data_dict = {}\n",
    "\n",
    "    # Loop through the dictionary, load, transform, and store the data\n",
    "    for key, file_path in data_files.items():\n",
    "        X, y = load_and_transform_data(file_path)\n",
    "        data_dict[f\"X_{key}.pkl\"] = X\n",
    "        data_dict[f\"y_{key}.pkl\"] = y\n",
    "\n",
    "    for filename, data in data_dict.items():\n",
    "        save_p(filename, data)\n",
    "\n",
    "    word_dict, tag_dict = create_corpus(data_dict[\"X_train.pkl\"], data_dict[\"y_train.pkl\"])\n",
    "    save_p(\"sequence_list.pkl\", sequence_list)\n",
    "\n",
    "else:\n",
    "    X_train=load_p(\"X_train.pkl\")\n",
    "    y_train=load_p(\"y_train.pkl\")\n",
    "\n",
    "    word_dict, tag_dict = create_corpus(X_train,y_train)\n",
    "    save_p(\"sequence_list.pkl\", sequence_list)\n",
    "\n",
    "    sequence_list = create_sequence_list(X_train, y_train, word_dict, tag_dict)\n",
    "\n",
    "    sequence_list=load_p(\"sequence_list.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Accuracy: 0.893815\n",
      "Epoch: 1 Accuracy: 0.931674\n",
      "Epoch: 2 Accuracy: 0.940913\n",
      "Epoch: 3 Accuracy: 0.946175\n",
      "Epoch: 4 Accuracy: 0.950018\n",
      "Epoch: 5 Accuracy: 0.952577\n",
      "Epoch: 6 Accuracy: 0.954425\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed eval>:1\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Nainh\\Proton Drive\\nainho1306 (1)\\My files\\UB\\Segundo Semestre\\NLP\\Assigment 2\\NLP\\Assignment_2\\skseq\\sequences\\structured_perceptron.py:46\u001b[0m, in \u001b[0;36mStructuredPerceptron.fit\u001b[1;34m(self, dataset, num_epochs)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mWarning: Model already trained\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 46\u001b[0m     acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m Accuracy: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch, acc))\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maveraged:\n",
      "File \u001b[1;32mc:\\Users\\Nainh\\Proton Drive\\nainho1306 (1)\\My files\\UB\\Segundo Semestre\\NLP\\Assigment 2\\NLP\\Assignment_2\\skseq\\sequences\\structured_perceptron.py:82\u001b[0m, in \u001b[0;36mStructuredPerceptron.fit_epoch\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_examples):\n\u001b[0;32m     81\u001b[0m     sequence \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mseq_list[i]\n\u001b[1;32m---> 82\u001b[0m     num_labels, num_mistakes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperceptron_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m     num_labels_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m num_labels\n\u001b[0;32m     84\u001b[0m     num_mistakes_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m num_mistakes\n",
      "File \u001b[1;32mc:\\Users\\Nainh\\Proton Drive\\nainho1306 (1)\\My files\\UB\\Segundo Semestre\\NLP\\Assigment 2\\NLP\\Assignment_2\\skseq\\sequences\\structured_perceptron.py:118\u001b[0m, in \u001b[0;36mStructuredPerceptron.perceptron_update\u001b[1;34m(self, sequence)\u001b[0m\n\u001b[0;32m    115\u001b[0m num_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    116\u001b[0m num_mistakes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 118\u001b[0m predicted_sequence, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mviterbi_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m predicted_sequence\u001b[38;5;241m.\u001b[39my\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# Update initial features.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nainh\\Proton Drive\\nainho1306 (1)\\My files\\UB\\Segundo Semestre\\NLP\\Assigment 2\\NLP\\Assignment_2\\skseq\\sequences\\sequence_classifier.py:133\u001b[0m, in \u001b[0;36mSequenceClassifier.viterbi_decode\u001b[1;34m(self, sequence)\u001b[0m\n\u001b[0;32m    129\u001b[0m initial_scores, transition_scores, final_scores, emission_scores \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_scores(sequence)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Run the forward algorithm.\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m best_states, total_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_viterbi\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mtransition_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mfinal_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43memission_scores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m predicted_sequence \u001b[38;5;241m=\u001b[39m sequence\u001b[38;5;241m.\u001b[39mcopy_sequence()\n\u001b[0;32m    139\u001b[0m predicted_sequence\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m best_states\n",
      "File \u001b[1;32mc:\\Users\\Nainh\\Proton Drive\\nainho1306 (1)\\My files\\UB\\Segundo Semestre\\NLP\\Assigment 2\\NLP\\Assignment_2\\skseq\\sequences\\sequence_classification_decoder.py:110\u001b[0m, in \u001b[0;36mSequenceClassificationDecoder.run_viterbi\u001b[1;34m(self, initial_scores, transition_scores, final_scores, emission_scores)\u001b[0m\n\u001b[0;32m    106\u001b[0m         viterbi_scores[pos, current_state] \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    107\u001b[0m             np\u001b[38;5;241m.\u001b[39mmax(viterbi_scores[pos\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;241m+\u001b[39m transition_scores[pos\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, current_state, :])\n\u001b[0;32m    108\u001b[0m         viterbi_scores[pos, current_state] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m emission_scores[pos, current_state]\n\u001b[0;32m    109\u001b[0m         viterbi_paths[pos, current_state] \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m--> 110\u001b[0m             \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mviterbi_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpos\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtransition_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpos\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Termination.\u001b[39;00m\n\u001b[0;32m    112\u001b[0m best_score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(viterbi_scores[length\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;241m+\u001b[39m final_scores)\n",
      "File \u001b[1;32mc:\\Users\\Nainh\\.conda\\envs\\quora_test_env\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:1229\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m-> 1229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nainh\\.conda\\envs\\quora_test_env\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =========== MODELS - DEFAULT FEATURES ===========\n",
    "\n",
    "# =========== GET FEATURES ===========\n",
    "mapping_feature = IDFeatures(sequence_list)\n",
    "mapping_feature.build_features()\n",
    "\n",
    "# =========== MODEL PARAMETERS ===========\n",
    "epochs = 15\n",
    "structured_perceptron = StructuredPerceptron(word_dict, tag_dict, mapping_feature)\n",
    "structured_perceptron.num_epochs = 5\n",
    "\n",
    "# =========== MODEL TRAIN ===========\n",
    "%time structured_perceptron.fit(mapping_feature.dataset, epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== MODEL SAVE ===========\n",
    "#structured_perceptron.save_model(\"fitted_models/default_features_model_wo_cython.pkl\")\n",
    "\n",
    "save_p(\"default_features_model_wo_cython.pkl\", structured_perceptron)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "Epoch: 0 Accuracy: 0.932172\n",
      "Epoch: 1 Accuracy: 0.946864\n",
      "Epoch: 2 Accuracy: 0.950514\n",
      "Epoch: 3 Accuracy: 0.953234\n",
      "Epoch: 4 Accuracy: 0.955109\n",
      "Epoch: 5 Accuracy: 0.956550\n",
      "Epoch: 6 Accuracy: 0.957786\n",
      "Epoch: 7 Accuracy: 0.958589\n",
      "Epoch: 8 Accuracy: 0.959384\n",
      "Epoch: 9 Accuracy: 0.960120\n",
      "Epoch: 10 Accuracy: 0.960703\n",
      "Epoch: 11 Accuracy: 0.961394\n",
      "Epoch: 12 Accuracy: 0.961745\n",
      "Epoch: 13 Accuracy: 0.962609\n",
      "Epoch: 14 Accuracy: 0.962600\n"
     ]
    }
   ],
   "source": [
    "# # =========== MODELS - ADDED FEATURES ===========\n",
    "\n",
    "from skseq.sequences import extended_feature\n",
    "\n",
    "\n",
    "# =========== GET FEATURES ===========\n",
    "extra_mapping_feature = extended_feature.ExtendedFeatures(sequence_list) \n",
    "extra_mapping_feature.build_features()\n",
    "\n",
    "# =========== MODEL PARAMETERS ===========\n",
    "epochs = 15\n",
    "structured_perceptron_extra = StructuredPerceptron(word_dict, tag_dict, extra_mapping_feature)\n",
    "structured_perceptron_extra.num_epochs = 5\n",
    "%time \n",
    "structured_perceptron_extra.fit(extra_mapping_feature.dataset, epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_p(\"extra_features_model_wo_cython.pkl\",structured_perceptron_extra)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
