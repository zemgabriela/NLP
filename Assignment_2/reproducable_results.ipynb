{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPARING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== IMPORT UTILS ===========\n",
    "from utils.utils import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset and sequance list\n",
    "\n",
    "def load_p(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        df_ = pickle.load(file)\n",
    "    return(df_)\n",
    "\n",
    "X_train=load_p(\"fitted_models/X_train.pkl\")\n",
    "y_train=load_p(\"fitted_models/y_train.pkl\")\n",
    "\n",
    "X_test=load_p(\"fitted_models/X_test.pkl\")\n",
    "y_test=load_p(\"fitted_models/y_test.pkl\")\n",
    "\n",
    "X_tiny=load_p(\"fitted_models/X_tiny.pkl\")\n",
    "y_tiny=load_p(\"fitted_models/y_tiny.pkl\")\n",
    "\n",
    "sequence_list = load_p(\"fitted_models/sequence_list.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== CREATE DICTIONARIES WITH UNIQUE INDEX  ===========\n",
    "\n",
    "# To store values efficiently (INTEGERS/WORDS and INTEGERS/TAGS)\n",
    "# x attribute: list of words (integer words)\n",
    "# y attribute: list of tags (integer tags)\n",
    "# Then we need to keep a mapping from integers to words and from integers to tags.\n",
    "\n",
    "word_dict, tag_dict = create_corpus(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== CREATE TAGS  ===========\n",
    "\n",
    "train_tag_pos = [[tag_dict[i] for i in tag] for tag in y_train]\n",
    "y_train_true = [tag for array in train_tag_pos for tag in array]\n",
    "\n",
    "test_tag_pos = [[tag_dict[i] for i in tag] for tag in y_test]\n",
    "y_test_true = [tag for array in test_tag_pos for tag in array]\n",
    "\n",
    "tiny_tag_pos = [[tag_dict[i] for i in tag] for tag in y_tiny]\n",
    "y_tiny_true = [tag for array in tiny_tag_pos for tag in array]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.,  9., 11., ..., -2.,  2.,  0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# =========== MODELS - Default Features ===========\n",
    "feature_mapper = IDFeatures(sequence_list)\n",
    "feature_mapper.build_features()\n",
    "\n",
    "# =========== MODELS IMPORT  ===========\n",
    "\n",
    "structured_perceptron = StructuredPerceptron(word_dict, tag_dict, feature_mapper)\n",
    "structured_perceptron.load_model(dir='fitted_models/default_features_model_wo_cython.pkl')\n",
    "structured_perceptron.parameters\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting tags:   4%|‚ñç         | 1656/38367 [00:15<05:42, 107.08sequence/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstructured_perceptron\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtag_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nainh\\Proton Drive\\nainho1306 (1)\\My files\\UB\\Segundo Semestre\\NLP\\Assigment 2\\NLP\\Assignment_2\\utils\\utils.py:216\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(data_, model, y_true, tag_dict)\u001b[0m\n\u001b[0;32m    213\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data_)), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicting tags\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 216\u001b[0m     predicted_tag \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_tags_given_words\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(predicted_tag)\n\u001b[0;32m    219\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mndarray\u001b[38;5;241m.\u001b[39mtolist(array) \u001b[38;5;28;01mfor\u001b[39;00m array \u001b[38;5;129;01min\u001b[39;00m predictions]\n",
      "File \u001b[1;32mc:\\Users\\Nainh\\Proton Drive\\nainho1306 (1)\\My files\\UB\\Segundo Semestre\\NLP\\Assigment 2\\NLP\\Assignment_2\\skseq\\sequences\\structured_perceptron.py:92\u001b[0m, in \u001b[0;36mStructuredPerceptron.predict_tags_given_words\u001b[1;34m(self, words)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_tags_given_words\u001b[39m(\u001b[38;5;28mself\u001b[39m, words):\n\u001b[0;32m     91\u001b[0m     sequence \u001b[38;5;241m=\u001b[39m  seq\u001b[38;5;241m.\u001b[39mSequence(x\u001b[38;5;241m=\u001b[39mwords, y\u001b[38;5;241m=\u001b[39mwords)\n\u001b[1;32m---> 92\u001b[0m     predicted_sequence, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mviterbi_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predicted_sequence\u001b[38;5;241m.\u001b[39my\n",
      "File \u001b[1;32mc:\\Users\\Nainh\\Proton Drive\\nainho1306 (1)\\My files\\UB\\Segundo Semestre\\NLP\\Assigment 2\\NLP\\Assignment_2\\skseq\\sequences\\sequence_classifier.py:130\u001b[0m, in \u001b[0;36mSequenceClassifier.viterbi_decode\u001b[1;34m(self, sequence)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the most likely sequence of states given the observations,\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;124;03mby running the Viterbi algorithm.\"\"\"\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# Compute scores given the observation sequence.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m initial_scores, transition_scores, final_scores, emission_scores \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Run the forward algorithm.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m best_states, total_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mrun_viterbi(initial_scores,\n\u001b[0;32m    134\u001b[0m                                                     transition_scores,\n\u001b[0;32m    135\u001b[0m                                                     final_scores,\n\u001b[0;32m    136\u001b[0m                                                     emission_scores)\n",
      "File \u001b[1;32mc:\\Users\\Nainh\\Proton Drive\\nainho1306 (1)\\My files\\UB\\Segundo Semestre\\NLP\\Assigment 2\\NLP\\Assignment_2\\skseq\\sequences\\discriminative_sequence_classifier.py:30\u001b[0m, in \u001b[0;36mDiscriminativeSequenceClassifier.compute_scores\u001b[1;34m(self, sequence)\u001b[0m\n\u001b[0;32m     28\u001b[0m emission_scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros([length, num_states])\n\u001b[0;32m     29\u001b[0m initial_scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(num_states)\n\u001b[1;32m---> 30\u001b[0m transition_scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros([length\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, num_states, num_states])\n\u001b[0;32m     31\u001b[0m final_scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(num_states)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Initial position.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate(X_test,structured_perceptron,y_test_true,tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "evaluate() takes 2 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tiny\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstructured_perceptron\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_tiny_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtag_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: evaluate() takes 2 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "evaluate(X_tiny,structured_perceptron,y_tiny_true,tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skseq.sequences import extended_feature\n",
    "\n",
    "extra_mapping_feature = extended_feature.ExtendedFeatures(sequence_list) \n",
    "extra_mapping_feature.build_features()\n",
    "\n",
    "structured_perceptron_extraf = StructuredPerceptron(word_dict, tag_dict, extra_mapping_feature)\n",
    "structured_perceptron_extraf.load_model(dir='fitted_models/extra_features_model_wo_cython.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(X_test,structured_perceptron_extraf,y_test_true,tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(X_tiny,structured_perceptron_extraf,y_tiny_true,tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
